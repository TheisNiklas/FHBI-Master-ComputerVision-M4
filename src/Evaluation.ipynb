{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataLoader import DataLoader\n",
    "from utils.modelLoader import ModelLoader\n",
    "from utils.SiameseModel import SiameseModel\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(path: str):\n",
    "    image_size = (224, 224)\n",
    "    image_channels = 3\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(\n",
    "        img, channels=image_channels, expand_animations=False\n",
    "    )\n",
    "    img = tf.image.central_crop(img, 0.7)\n",
    "    img = tf.image.resize(img, image_size, method=\"bilinear\")\n",
    "    img.set_shape((image_size[0], image_size[1], image_channels))\n",
    "    return img\n",
    "\n",
    "def loadImages(path1:str, path2:str):\n",
    "    return (\n",
    "        loadImage(path1),\n",
    "        loadImage(path2)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Similarity: 0.93398213\n",
      "Similarity: 0.97547746\n",
      "Similarity: 0.89644086\n",
      "Similarity: 0.9726523\n",
      "Similarity: 0.8594779\n",
      "Similarity: 0.9604407\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    [\"../data/img_align_celeba/000791.jpg\",\"../data/img_align_celeba/012203.jpg\"],\n",
    "    [\"../data/img_align_celeba/000791.jpg\", \"../data/img_align_celeba/017522.jpg\"],\n",
    "    [\"../data/img_align_celeba/002345.jpg\", \"../data/img_align_celeba/014529.jpg\"],\n",
    "    [\"../data/img_align_celeba/000791.jpg\", \"../data/img_align_celeba/014529.jpg\"],\n",
    "    [\"../data/img_align_celeba/002345.jpg\", \"../data/img_align_celeba/000791.jpg\"],\n",
    "    [\"../data/img_align_celeba/017522.jpg\", \"../data/img_align_celeba/012203.jpg\"]\n",
    "]\n",
    "metaData = pd.DataFrame(data, columns=[\"anchor\", \"compare\"])\n",
    "\n",
    "anchor_images = metaData[\"anchor\"]\n",
    "compare_images = metaData[\"compare\"]\n",
    "\n",
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "positive_dataset = tf.data.Dataset.from_tensor_slices(compare_images)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset))\n",
    "dataset = dataset.map(loadImages)\n",
    "\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "embedding: tf.keras.Model = tf.keras.models.load_model(\"../models/Siamese_MobileNetV1_Train5000_All_embedding\")\n",
    "\n",
    "for sample in iter(dataset):\n",
    "    anchor, compare = sample\n",
    "\n",
    "    anchor_embedding, compare_embedding = (\n",
    "        embedding(tf.keras.applications.mobilenet.preprocess_input(anchor)),\n",
    "        embedding(tf.keras.applications.mobilenet.preprocess_input(compare)),\n",
    "    )\n",
    "    \n",
    "    cosine_similarity = tf.keras.metrics.CosineSimilarity()\n",
    "    positive_similarity = cosine_similarity(anchor_embedding, compare_embedding)\n",
    "\n",
    "    print(\"Similarity:\", positive_similarity.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor's shape (224, 224, 3) is not compatible with supplied shape (None, 224, 224, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m embedding: tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39m../models/Siamese_MobileNetV1_Train5000_All_embedding\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m anchor \u001b[39m=\u001b[39m loadImage(\u001b[39m\"\u001b[39;49m\u001b[39m../data/img_align_celeba/000791.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m compare \u001b[39m=\u001b[39m loadImage(\u001b[39m\"\u001b[39m\u001b[39m../data/img_align_celeba/012203.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m anchor_embedding, compare_embedding \u001b[39m=\u001b[39m (\n\u001b[0;32m      7\u001b[0m     embedding\u001b[39m.\u001b[39mpredict(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mapplications\u001b[39m.\u001b[39mmobilenet\u001b[39m.\u001b[39mpreprocess_input(anchor)),\n\u001b[0;32m      8\u001b[0m     embedding\u001b[39m.\u001b[39mpredict(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mapplications\u001b[39m.\u001b[39mmobilenet\u001b[39m.\u001b[39mpreprocess_input(compare)),\n\u001b[0;32m      9\u001b[0m )\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36mloadImage\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      8\u001b[0m img \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mcentral_crop(img, \u001b[39m0.7\u001b[39m)\n\u001b[0;32m      9\u001b[0m img \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mresize(img, image_size, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m img\u001b[39m.\u001b[39;49mset_shape((\u001b[39mNone\u001b[39;49;00m, image_size[\u001b[39m0\u001b[39;49m], image_size[\u001b[39m1\u001b[39;49m], image_channels))\n\u001b[0;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32ml:\\Pogrammier Projekte\\FHBielefeld\\Master\\ComputerVisionPraktikum\\Milestone4\\.env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1301\u001b[0m, in \u001b[0;36m_EagerTensorBase.set_shape\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_shape\u001b[39m(\u001b[39mself\u001b[39m, shape):\n\u001b[0;32m   1300\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mis_compatible_with(shape):\n\u001b[1;32m-> 1301\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTensor\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m is not compatible \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1302\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith supplied shape \u001b[39m\u001b[39m{\u001b[39;00mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor's shape (224, 224, 3) is not compatible with supplied shape (None, 224, 224, 3)."
     ]
    }
   ],
   "source": [
    "embedding: tf.keras.Model = tf.keras.models.load_model(\"../models/Siamese_MobileNetV1_Train5000_All_embedding\")\n",
    "\n",
    "anchor = loadImage(\"../data/img_align_celeba/000791.jpg\")\n",
    "compare = loadImage(\"../data/img_align_celeba/012203.jpg\")\n",
    "\n",
    "anchor_embedding, compare_embedding = (\n",
    "    embedding.predict(tf.keras.applications.mobilenet.preprocess_input(anchor)),\n",
    "    embedding.predict(tf.keras.applications.mobilenet.preprocess_input(compare)),\n",
    ")\n",
    "\n",
    "cosine_similarity = tf.keras.metrics.CosineSimilarity()\n",
    "positive_similarity = cosine_similarity(anchor_embedding, compare_embedding)\n",
    "\n",
    "print(\"Similarity:\", positive_similarity.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1650262b3ee0ad320e518d32138bb4c67705e5f1b5fd0593bdd8b873d187d5fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
