{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../data_meta/img_align_celeba/identity_CelebA.txt\", delim_whitespace=True, names=[\"filename\", \"identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"filename\"] = metadata[\"filename\"].apply(lambda x: os.path.join(\"../data/img_align_celeba/\", x)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_grouped = metadata.groupby(\"identity\")['filename'].apply(list).reset_index(name='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>../data/img_align_celeba/002345.jpg</td>\n",
       "      <td>8223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename  identity\n",
       "2344  ../data/img_align_celeba/002345.jpg      8223"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[metadata[\"filename\"] == \"../data/img_align_celeba/002345.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['../data/img_align_celeba/002345.jpg', '../data/img_align_celeba/010867.jpg', '../data/img_align_celeba/014529.jpg', '../data/img_align_celeba/018200.jpg', '../data/img_align_celeba/019831.jpg', '../data/img_align_celeba/028330.jpg', '../data/img_align_celeba/039247.jpg', '../data/img_align_celeba/061440.jpg', '../data/img_align_celeba/067691.jpg', '../data/img_align_celeba/071881.jpg', '../data/img_align_celeba/079908.jpg', '../data/img_align_celeba/094869.jpg', '../data/img_align_celeba/097951.jpg', '../data/img_align_celeba/108561.jpg', '../data/img_align_celeba/114813.jpg', '../data/img_align_celeba/116942.jpg', '../data/img_align_celeba/127437.jpg', '../data/img_align_celeba/130786.jpg', '../data/img_align_celeba/133654.jpg', '../data/img_align_celeba/161321.jpg'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_grouped[metadata_grouped[\"identity\"] == 8223][\"filename\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempCount = metadata_grouped['filename'].str.len()\n",
    "metadata_grouped_cleaned = metadata_grouped.drop(metadata_grouped[tempCount < 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "includeAll = True\n",
    "\n",
    "metadata_triplet_list_identityOnce = list()\n",
    "metadata_triplet_list_all = list()\n",
    "\n",
    "rand_gen = random.Random(123)\n",
    "size = len(metadata_grouped_cleaned.index)\n",
    "\n",
    "for index, row in metadata_grouped_cleaned.iterrows():\n",
    "    if not includeAll:\n",
    "        rand_negative_x = index\n",
    "        while rand_negative_x == index:\n",
    "            rand_negative_x = rand_gen.randint(0, size-1)\n",
    "        negative_size = metadata_grouped_cleaned.iloc[rand_negative_x]['filename'].__len__()\n",
    "        rand_negative_y = rand_gen.randint(0,negative_size-1)\n",
    "        negative = metadata_grouped_cleaned.iloc[rand_negative_x]['filename'][rand_negative_y]\n",
    "        anchor = row[\"filename\"][0]\n",
    "        positive = row[\"filename\"][1]\n",
    "        metadata_triplet_list_identityOnce.append([anchor, positive, negative])\n",
    "    else:\n",
    "        imagesUsed = 0\n",
    "        imagesTotal = row[\"filename\"].__len__()\n",
    "        while imagesUsed + 2 <= imagesTotal:\n",
    "            rand_negative_x = index\n",
    "            while rand_negative_x == index:\n",
    "                rand_negative_x = rand_gen.randint(0, size-1)\n",
    "            negative_size = metadata_grouped_cleaned.iloc[rand_negative_x]['filename'].__len__()\n",
    "            rand_negative_y = rand_gen.randint(0,negative_size-1)\n",
    "            negative = metadata_grouped_cleaned.iloc[rand_negative_x]['filename'][rand_negative_y]\n",
    "            anchor = row[\"filename\"][imagesUsed]\n",
    "            positive = row[\"filename\"][imagesUsed+1]\n",
    "            metadata_triplet_list_all.append([anchor, positive, negative])\n",
    "            imagesUsed = imagesUsed + 2\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_triplet_identityOnce = pd.DataFrame(metadata_triplet_list_identityOnce, columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_identityOnce_limit50 = pd.DataFrame(metadata_triplet_list_identityOnce[:50], columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_identityOnce_limit100 = pd.DataFrame(metadata_triplet_list_identityOnce[:100], columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_identityOnce_limit500 = pd.DataFrame(metadata_triplet_list_identityOnce[:500], columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_identityOnce_limit1000 = pd.DataFrame(metadata_triplet_list_identityOnce[:1000], columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_identityOnce_limit5000 = pd.DataFrame(metadata_triplet_list_identityOnce[:5000], columns=[\"anchor\",\"positive\", \"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_triplet_identityOnce.to_json(\"../data_meta/img_align_celeba/processed/metadate_identity-once.json\")\n",
    "metadata_triplet_identityOnce_limit50.to_json(\"../data_meta/img_align_celeba/processed/metadate_identity-once_limit50.json\")\n",
    "metadata_triplet_identityOnce_limit100.to_json(\"../data_meta/img_align_celeba/processed/metadate_identity-once_limit100.json\")\n",
    "metadata_triplet_identityOnce_limit500.to_json(\"../data_meta/img_align_celeba/processed/metadate_identity-once_limit500.json\")\n",
    "metadata_triplet_identityOnce_limit1000.to_json(\"../data_meta/img_align_celeba/processed/metadate_identity-once_limit1000.json\")\n",
    "metadata_triplet_identityOnce_limit5000.to_json(\"../data_meta/img_align_celeba/processed/metadate_identity-once_limit5000.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_triplet_all = pd.DataFrame(metadata_triplet_list_all, columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_all_limit50 = pd.DataFrame(metadata_triplet_list_all[:50], columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_all_limit100 = pd.DataFrame(metadata_triplet_list_all[:100], columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_all_limit500 = pd.DataFrame(metadata_triplet_list_all[:500], columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_all_limit1000 = pd.DataFrame(metadata_triplet_list_all[:1000], columns=[\"anchor\",\"positive\", \"negative\"])\n",
    "metadata_triplet_all_limit5000 = pd.DataFrame(metadata_triplet_list_all[:5000], columns=[\"anchor\",\"positive\", \"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_triplet_all.to_json(\"../data_meta/img_align_celeba/processed/metadate_all.json\")\n",
    "metadata_triplet_all_limit50.to_json(\"../data_meta/img_align_celeba/processed/metadate_all_limit50.json\")\n",
    "metadata_triplet_all_limit100.to_json(\"../data_meta/img_align_celeba/processed/metadate_all_limit100.json\")\n",
    "metadata_triplet_all_limit500.to_json(\"../data_meta/img_align_celeba/processed/metadate_all_limit500.json\")\n",
    "metadata_triplet_all_limit1000.to_json(\"../data_meta/img_align_celeba/processed/metadate_all_limit1000.json\")\n",
    "metadata_triplet_all_limit5000.to_json(\"../data_meta/img_align_celeba/processed/metadate_all_limit5000.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../data_meta/img_align_celeba/identity_CelebA.txt\", delim_whitespace=True, names=[\"filename\", \"identity\"])\n",
    "metadata[\"filename\"] = metadata[\"filename\"].apply(lambda x: os.path.join(\"../data/img_align_celeba/\", x)).astype(str)\n",
    "metadata_grouped = metadata.groupby(\"identity\")['filename'].apply(list).reset_index(name='filename')\n",
    "tempCount = metadata_grouped['filename'].str.len()\n",
    "metadata_grouped_cleaned = metadata_grouped.drop(metadata_grouped[tempCount < 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_pair_list = list()\n",
    "limit_identities = 2000\n",
    "\n",
    "rand_gen = random.Random(123)\n",
    "size = len(metadata_grouped_cleaned.index)\n",
    "\n",
    "tempIdentity = metadata_grouped_cleaned[\"identity\"].astype(int)\n",
    "\n",
    "metadata_grouped_cleaned_limit = metadata_grouped_cleaned.drop(metadata_grouped_cleaned[tempIdentity >= limit_identities].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = random.Random(123)\n",
    "size = len(metadata_grouped_cleaned.index)\n",
    "\n",
    "for index, row in metadata_grouped_cleaned_limit.iterrows():\n",
    "    rand_positive = 0\n",
    "    while rand_positive == 0:\n",
    "        rand_positive = rand_gen.randint(0, len(row['filename'])-1)\n",
    "    \n",
    "    rand_negative_x = index\n",
    "    while rand_negative_x == index:\n",
    "        rand_negative_x = rand_gen.randint(0, size-1)\n",
    "    negative_size = metadata_grouped_cleaned.iloc[rand_negative_x]['filename'].__len__()\n",
    "    rand_negative_y = rand_gen.randint(0,negative_size-1)\n",
    "    anchor = row[\"filename\"][0]\n",
    "    positive = row[\"filename\"][rand_positive]\n",
    "    negative = metadata_grouped_cleaned.iloc[rand_negative_x]['filename'][rand_negative_y]\n",
    "    metadata_pair_list.append([anchor, positive, 1])\n",
    "    metadata_pair_list.append([anchor, negative, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_pair = pd.DataFrame(metadata_pair_list, columns=[\"anchor\",\"compare\", \"label\"])\n",
    "metadata_pair.to_json(\"../data_meta/img_align_celeba/processed/metadate_pairs_limit5000.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_pair_list = list()\n",
    "limit_identities = 500\n",
    "\n",
    "rand_gen = random.Random(123)\n",
    "size = len(metadata_grouped_cleaned.index)\n",
    "\n",
    "tempIdentity = metadata_grouped_cleaned[\"identity\"].astype(int)\n",
    "\n",
    "metadata_grouped_cleaned_limit = metadata_grouped_cleaned.drop(metadata_grouped_cleaned[tempIdentity >= limit_identities].index)\n",
    "\n",
    "rand_gen = random.Random(123)\n",
    "size = len(metadata_grouped_cleaned.index)\n",
    "\n",
    "for index, row in metadata_grouped_cleaned_limit.iterrows():\n",
    "    usedImages = 0\n",
    "    while usedImages < len(row['filename']):\n",
    "        rand_positive = usedImages\n",
    "        while rand_positive == usedImages:\n",
    "            rand_positive = rand_gen.randint(0, len(row['filename'])-1)\n",
    "        \n",
    "        rand_negative_x = index\n",
    "        while rand_negative_x == index:\n",
    "            rand_negative_x = rand_gen.randint(0, size-1)\n",
    "        negative_size = metadata_grouped_cleaned.iloc[rand_negative_x]['filename'].__len__()\n",
    "        rand_negative_y = rand_gen.randint(0,negative_size-1)\n",
    "        anchor = row[\"filename\"][usedImages]\n",
    "        positive = row[\"filename\"][rand_positive]\n",
    "        negative = metadata_grouped_cleaned.iloc[rand_negative_x]['filename'][rand_negative_y]\n",
    "        metadata_pair_list.append([anchor, positive, 1])\n",
    "        metadata_pair_list.append([anchor, negative, 0])\n",
    "        usedImages = usedImages+1\n",
    "    \n",
    "metadata_pair = pd.DataFrame(metadata_pair_list, columns=[\"anchor\",\"compare\", \"label\"])\n",
    "metadata_pair.to_json(\"../data_meta/img_align_celeba/processed/metadate_pairs_all_limit500.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1650262b3ee0ad320e518d32138bb4c67705e5f1b5fd0593bdd8b873d187d5fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
